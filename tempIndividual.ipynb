{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import folium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "root = \"C://Users//user//Desktop//Helmholtz//Tasks//Task 1//\"\n",
    "\n",
    "\n",
    "def get_all_basin_coords():\n",
    "    basins_dir = \"Basin_Boundaries//\"\n",
    "    mopex_dir = \"MOPEX//\"\n",
    "    \n",
    "    #basin_file_names = [f for f in listdir(join(root, basins_dir)) if isfile(join(root, basins_dir, f))]\n",
    "    # below basins are present in mopex dataset\n",
    "    basin_file_names = [f.replace('.txt', '.BDY') for f in listdir(join(root, mopex_dir)) if isfile(join(root, mopex_dir, f))]\n",
    "    basin_file_names = basin_file_names[:-2]\n",
    "    #basin_file_names = [\"01048000.BDY\", \"01055500.BDY\",\"01060000.BDY\", \"01064500.BDY\", \"01076500.BDY\"]\n",
    "        \n",
    "    all_basin_geoms = []\n",
    "    for file_name in basin_file_names[:]:\n",
    "        lat_point_list = []\n",
    "        lon_point_list = []\n",
    "        df = pd.read_csv(join(root, basins_dir, file_name), delim_whitespace=True, header=None, skiprows=1)\n",
    "        lat_point_list = df[1]\n",
    "        lon_point_list = df[0]\n",
    "    \n",
    "        polygon_geom = Polygon(zip(lon_point_list, lat_point_list))\n",
    "        all_basin_geoms.append(polygon_geom)\n",
    "         \n",
    "    return all_basin_geoms, basin_file_names\n",
    "\n",
    " \n",
    "def read_prism_hdr(hdr_path):\n",
    "    \"\"\"Read an ESRI BIL HDR file\"\"\"\n",
    "    with open(hdr_path, 'r') as input_f:\n",
    "        header_list = input_f.readlines()\n",
    "    return dict(item.strip().split() for item in header_list)\n",
    " \n",
    "def read_prism_bil(bil_path):\n",
    "    \"\"\"Read an array from ESRI BIL raster file\"\"\"\n",
    "    hdr_dict = read_prism_hdr(bil_path.replace('.bil', '.hdr'))\n",
    "    \n",
    "    prism_array = np.fromfile(bil_path, dtype=np.float32)\n",
    "    prism_array = prism_array.reshape(\n",
    "        int(hdr_dict['NROWS']), int(hdr_dict['NCOLS']))\n",
    "    prism_array[prism_array == float(hdr_dict['NODATA'])] = np.nan\n",
    "    return prism_array\n",
    "\n",
    "def get_ppt_data(year,month):\n",
    "    prism_dir = \"PRISM_ppt_stable_4kmM3_198101_202001_bil//\"\n",
    "    if(month<10):\n",
    "        prism_file_path = \"PRISM_ppt_stable_4kmM3_\"+str(year)+\"0\"+str(month)+\"_bil.bil\"\n",
    "    else:\n",
    "        prism_file_path = \"PRISM_ppt_stable_4kmM3_\"+str(year)+str(month)+\"_bil.bil\"    \n",
    "    ppt_data = read_prism_bil(join(root, prism_dir, prism_file_path))\n",
    "    \n",
    "    hdr_dict = read_prism_hdr(join(root, prism_dir, prism_file_path).replace('.bil', '.hdr'))\n",
    "    \n",
    "    hdr_dict[\"ULXMAP\"] = float(hdr_dict[\"ULXMAP\"])\n",
    "    hdr_dict[\"ULYMAP\"] = float(hdr_dict[\"ULYMAP\"])\n",
    "    hdr_dict['NROWS'] = int(hdr_dict['NROWS'])\n",
    "    hdr_dict['NCOLS'] = int(hdr_dict['NCOLS'])\n",
    "    hdr_dict['XDIM'] = float(hdr_dict['XDIM'])\n",
    "    hdr_dict['YDIM'] = float(hdr_dict['YDIM'])\n",
    "    \n",
    "    p1 = (hdr_dict[\"ULXMAP\"] - (hdr_dict['XDIM']/2), \n",
    "          hdr_dict[\"ULYMAP\"] + (hdr_dict['XDIM']/2))\n",
    "\n",
    "    p2 = (hdr_dict[\"ULXMAP\"] + hdr_dict['NCOLS']*hdr_dict['XDIM'],\n",
    "          hdr_dict[\"ULYMAP\"] + (hdr_dict['XDIM']/2))\n",
    "\n",
    "    p3 = (hdr_dict[\"ULXMAP\"] + hdr_dict['NCOLS']*hdr_dict['XDIM'],\n",
    "          hdr_dict[\"ULYMAP\"] - hdr_dict['NROWS']*hdr_dict['YDIM'])\n",
    "\n",
    "    p4 = (hdr_dict[\"ULXMAP\"] - (hdr_dict['XDIM']/2),\n",
    "          hdr_dict[\"ULYMAP\"] - hdr_dict['NROWS']*hdr_dict['YDIM'])\n",
    "    \n",
    "    lon_point_list = (p1[0], p2[0], p3[0], p4[0])\n",
    "    lat_point_list = (p1[1], p2[1], p3[1], p4[1])\n",
    "        \n",
    "    ppt_bounds = Polygon(zip(lon_point_list, lat_point_list))\n",
    "    \n",
    "    return ppt_bounds, ppt_data, hdr_dict\n",
    "\n",
    "def convert_pptData_to_GDF(ppt_bounds, ppt_data, hdr_dict): \n",
    "    Xmin, Ymin, Xmax, Ymax = ppt_bounds.bounds\n",
    "    \n",
    "    Xlength = int((Xmax - Xmin)/hdr_dict['XDIM'])\n",
    "    Ylength = int((Ymax - Ymin)/hdr_dict['YDIM'])\n",
    "    \n",
    "    xx, yy = np.meshgrid(np.linspace(Xmin, Xmax, Xlength), np.linspace(Ymin, Ymax, Ylength))\n",
    "    xc = xx.flatten()\n",
    "    yc = yy.flatten()\n",
    "    ppt_data = ppt_data.flatten()\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        {'Precipitation': ppt_data,\n",
    "         'Latitude': yc,\n",
    "         'Longitude': xc})\n",
    "        \n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Longitude, df.Latitude))\n",
    "\n",
    "    return gdf\n",
    "def plot_basins(basin_geoms):\n",
    "    crs = {'init': 'epsg:4326'}\n",
    "    m = folium.Map(zoom_start=10, tiles='cartodbpositron')\n",
    "\n",
    "    for basin_geom in basin_geoms:\n",
    "        polygon = gpd.GeoDataFrame(index=[0], crs=crs, geometry=[basin_geom])       \n",
    "\n",
    "        folium.GeoJson(polygon).add_to(m)\n",
    "        folium.LatLngPopup().add_to(m)\n",
    "        \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_basins(basin_geoms):\n",
    "    crs = {'init': 'epsg:4326'}\n",
    "    m = folium.Map(zoom_start=10, tiles='cartodbpositron')\n",
    "\n",
    "    for basin_geom in basin_geoms:\n",
    "        polygon = gpd.GeoDataFrame(index=[0], crs=crs, geometry=[basin_geom])       \n",
    "\n",
    "        folium.GeoJson(polygon).add_to(m)\n",
    "        folium.LatLngPopup().add_to(m)\n",
    "        \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_basin_geom_to_GDF(basin):\n",
    "        \n",
    "    longs, lats = basin.exterior.coords.xy\n",
    "\n",
    "    df = pd.DataFrame({'Latitude': longs,\n",
    "                       'Longitude': lats})\n",
    "        \n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Longitude, df.Latitude))\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    all_basin_geoms, basin_file_names = get_all_basin_coords()\n",
    "    ppt_bounds, ppt_data, hdr_dict = get_ppt_data(year=1987, month=8)\n",
    "    \n",
    "    ppt_gdf = convert_pptData_to_GDF(ppt_bounds, ppt_data, hdr_dict)\n",
    "    all_basin_gdf = []\n",
    "    for basin in all_basin_geoms:\n",
    "        basin_gdf = convert_basin_geom_to_GDF(basin)\n",
    "        all_basin_gdf.append(basin_gdf)    \n",
    "    \n",
    "    #plot_basins(all_basin_geoms)\n",
    "    #fig, ax = plt.subplots(1, 1)\n",
    "    #ppt_gdf.plot(column=\"Precipitation\", ax=ax, legend=True)\n",
    "\n",
    "    intersected = []\n",
    "    #clipped = gpd.clip(gdf=ppt_gdf, mask=all_basin_geoms[0])\n",
    "    spatial_index = ppt_gdf.sindex\n",
    "    \n",
    "    for count, basin_geom in enumerate(all_basin_geoms):\n",
    "        print(\"Index\", count)\n",
    "        print(\"basin_file_name:\", basin_file_names[count])    \n",
    "        possible_matches_index = list(spatial_index.intersection(basin_geom.bounds))\n",
    "        possible_matches = ppt_gdf.iloc[possible_matches_index]\n",
    "        precise_matches = possible_matches[possible_matches.intersects(basin_geom)]\n",
    "        \n",
    "        intersected.append(precise_matches)\n",
    "#    for count, basin_gdf in enumerate(all_basin_gdf):\n",
    "#        print(\"Index\", count)\n",
    "#        print(\"basin_file_name:\", basin_file_names[count])\n",
    "#        z=gpd.overlay(basin_gdf, ppt_gdf, how='intersection')\n",
    "#        if(z.shape[0]> 0):\n",
    "#            intersected.append(z)\n",
    "#            print(\"found\")\n",
    "#            \n",
    "    return intersected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0\n",
      "basin_file_name: 01048000.BDY\n"
     ]
    }
   ],
   "source": [
    "inter = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
